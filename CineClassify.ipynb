{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:60px; font-weight:bold;\">CineClassify</div>\n",
    "</div>\n",
    "<br>\n",
    "<p>In een wereld waar films in overvloed zijn, is er een groeiende behoefte om ze gemakkelijk en duidelijk te kunnen classificeren. Veel kijkers hebben geen goed overzicht over alle mengende genres en de vele nuances. Dit kan het zoeken van een leuke film voor op de vrijdagavond vanuit de Netflix catalogus of een trip naar de bios onnodig gecompliceerd maken.  \n",
    "\n",
    "Daarom heeft het nieuwe filmplatform “CineClassify” als doel om films automatisch te laten classificeren in verschillende genres en een duidelijke gids te brengen naar de kijkers. Om dit doel te bereiken hebben ze een data-science team ingehuurd om een model te maken die genres kan gaan voorspellen. Aan de hand van verschillende gegevens, bijv. cast, regisseur, reviews, etc., moet het mogelijk worden gemaakt om filmliefhebbers over de wereld te helpen om eenvoudiger films te vinden die passen bij hun smaak. \n",
    "\n",
    "In dit notebook werken we aan onze opdracht van CineClassify. Er zal een pipeline worden gebouwd om de data in te laden en er een dataframe van te maken. Dit dataframe kan worden gebruikt om de data duidelijk in te zien voor het datascience team.</p>\n",
    "<br>\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Inhoudsopgave</div>\n",
    "    <a name='begin'></a>\n",
    "</div>\n",
    "\n",
    "1. [Importeren van libaries](#start)\n",
    "2. [IMDb Webscraping](#ws)\n",
    "3. [Database: Movie Summaries](#db)\n",
    "4. [API](#api)\n",
    "5. [Preprocessing en Feature Engineering](#tr)\n",
    "6. [Opzetten van de Pipeline](#pipe)\n",
    "7. [Aantonen dat de Pipeline werkt](#toon)\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Importeren van libaries</div>\n",
    "    <a name='start'></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importeren standaard libaries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Importeren webscraping libaries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "\n",
    "# Importeren time-out libaries\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "# Importeren Database libaries\n",
    "import tarfile\n",
    "import os\n",
    "import urllib.request\n",
    "from io import BytesIO\n",
    "import sqlite3\n",
    "\n",
    "# Importeren API libabries\n",
    "import requests\n",
    "\n",
    "# Importeren Preprocessing libaries\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import json\n",
    "\n",
    "# Importeren FE libaries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">IMDb Webscraping</div>\n",
    "    <a name='ws'></a>\n",
    "</div>\n",
    "\n",
    "Om een deel van de data te krijgen is het nodig om data te verkrijgen van het internet. Dit wordt gedaan door middel van een techniek genaamd webscraping. Door middel van de BeautifulSoup library voor Python is het gemakkelijk gemaakt om deze stappen te ondernemen. Door het bekijken van de HTML code van de website kunnen de nodige elementen gevonden worden en kan de data opgehaald worden van de website. Voordat we beginnen met het coderen van de soup worden er eerst een paar nodige elementen aangemaakt.\n",
    "\n",
    "Om deze data te verkrijgen is er gebruik gemaakt van een webscraper. Deze webscraper is helaas niet meer bruikbaar doordat de source-code van de website volledig is veranderd. De code die gebruikt is om de data te verkrijgen is in de markdown cell gezet. Na de uitleg van de code, lezen we het csv bestand in dat gemaakt is na het uitvoeren van de code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "# Aanmaken van lijsten om de data in te stoppen\n",
    "titel = []\n",
    "jaartal = []\n",
    "lengte = []\n",
    "imdb_scores = []\n",
    "meta_scores = []\n",
    "stemmen = []\n",
    "us_omzet = []\n",
    "beschrijving = []\n",
    "certificaat = []\n",
    "genre = []\n",
    "regisseur = []\n",
    "sterren = []\n",
    "\n",
    "# Verkrijgen van de engelse namen van films\n",
    "en_titel = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "\n",
    "# Aanmaken van lijst voor pagina's\n",
    "pagina = np.arange(1, 1001, 50)\n",
    "\n",
    "# Aanmaken van de URL\n",
    "url = 'https://www.imdb.com/search/title/?groups=top_1000&sort=user_rating,desc&start='\n",
    "\n",
    "# Zorgen dat de scraping voor elke 50 gaat\n",
    "for p in pagina:\n",
    "    # Pakken van URL\n",
    "    p = requests.get(\n",
    "        url + str(p) + '&ref_=adv_nxt', headers=en_titel\n",
    "        )\n",
    "\n",
    "    # Beginnen van de soup\n",
    "    soup = BeautifulSoup(p.text, 'html.parser')\n",
    "\n",
    "    # Zoeken van alle films op de pagina\n",
    "    films = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "\n",
    "    # Wachtijd van 2 tot 10 seconden\n",
    "    sleep(randint(2, 10))\n",
    "\n",
    "    for item in films:\n",
    "        # Titel\n",
    "        titel.append(item.h3.a.text)\n",
    "\n",
    "        # Jaartal\n",
    "        jaartal.append(item.h3.find('span', class_='lister-item-year').text)\n",
    "\n",
    "        # Regisseur\n",
    "        regisseur.append(item.find('p', class_='').find('a').text)\n",
    "\n",
    "        # Hoofd-acteurs\n",
    "        acteurs = item.find('p', class_='').find_all('a')\n",
    "        stars = []\n",
    "        for tag in acteurs[-4:]:\n",
    "            stars.append(tag.text)\n",
    "        sterren.append(stars)\n",
    "\n",
    "        # Leeftijd certificatie\n",
    "        cert = (item.find('span', class_='certificate').text\n",
    "                if item.p.find('span', class_='certificate') else 'NotFound')\n",
    "        certificaat.append(cert)\n",
    "\n",
    "        # Lengte\n",
    "        runtime = (item.find('span', class_='runtime').text\n",
    "                    if item.p.find('span', class_='runtime') else 'NotFound')\n",
    "        lengte.append(runtime)\n",
    "\n",
    "        # Genre\n",
    "        gen = (item.find('span', class_='genre').text\n",
    "                if item.p.find('span', class_='genre') else 'NotFound')\n",
    "        genre.append(gen)\n",
    "\n",
    "        # IMDb rating\n",
    "        imdb_scores.append(float(item.strong.text))\n",
    "\n",
    "        # meta_scores\n",
    "        m_score = (item.find('span', class_='metascore').text\n",
    "                    if item.find('span', class_='metascore') else 'NotFound')\n",
    "        meta_scores.append(m_score)\n",
    "\n",
    "        # Beschrijving\n",
    "        desc = item.find_all('p', class_='text-muted')\n",
    "        beschrijving.append(desc[1].text)\n",
    "\n",
    "        # Stemmen en Omzet\n",
    "        so = item.find_all('span', attrs={'name':'nv'})\n",
    "        stemmen.append(so[0].text)\n",
    "        us_omzet.append(so[1].text if len(so) > 1 else '-')\n",
    "\n",
    "    print(\"-- Iteratie van loop voltooid --\")\n",
    "\n",
    "# Aanmaken van een dataframe\n",
    "films = pd.DataFrame(\n",
    "    {'Titel' : titel,\n",
    "     'Beschrijving' : beschrijving,\n",
    "     'Regisseur' : regisseur,\n",
    "     'Hoofd Acteurs' : sterren,\n",
    "     'Age_Rating' : certificaat,\n",
    "     'Genre' : genre,\n",
    "     'Jaar' : jaartal,\n",
    "     'Minuten' : lengte,\n",
    "     'IMDb_Score' : imdb_scores,\n",
    "     'Meta_Score' : meta_scores,\n",
    "     'Stemmen' : stemmen,\n",
    "     'Omzet (in M)' : us_omzet}\n",
    ")\n",
    "\n",
    "# Data preprocessing van de films dataframe\n",
    "# Opschonen van de omschrijving kolom\n",
    "films['Beschrijving'] = films['Omschrijving'].str.strip()\n",
    "\n",
    "# Opschonen van de acteurs kolom\n",
    "films['Hoofd Acteurs'] = films['Hoofd Acteurs'].astype(str)\\\n",
    "                            .replace({'\\'': '', '\\[|\\]': ''}, regex=True)\n",
    "\n",
    "# Opschonen van de genres kolom\n",
    "films['Genre'] = films['Genre'].str.strip()\n",
    "\n",
    "# Opschonen van de Jaar kolom\n",
    "films['Jaar'] = films['Jaar'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Opschonen van de Minuten kolom\n",
    "films['Minuten'] = films['Minuten'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Opschonen van de Meta_score kolom\n",
    "films['Meta_Score'] = films['Meta_Score'].str.extract('(\\d+)')\n",
    "\n",
    "# Omzetten naar float en NotFound veranderen naar NaN\n",
    "films['Meta_Score'] = pd.to_numeric(films['Meta_Score'], errors='coerce')\n",
    "\n",
    "# Opschonen van de Stemmen kolom\n",
    "films['Stemmen'] = films['Stemmen'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Opschonen van Omzet kolom\n",
    "# Weghalen van '$' en 'M'\n",
    "films['Omzet (in M)'] = films['Omzet (in M)'].map(lambda x: x.lstrip('$').rstrip('M'))\n",
    "\n",
    "# Omzetten naar float en NotFound veranderen naar NaN\n",
    "films['Omzet (in M)'] = pd.to_numeric(films['Omzet (in M)'], errors='coerce')\n",
    "\n",
    "films.to_csv('IMDb_data.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de bovenstaande code is het gelukt om de data van de voorgaande versie van IMDb te extraheren en de data alvast te preprocessen. Deze data is vervolgens in een CSV bestand gezet die nu zal worden ingeladen.\n",
    "\n",
    "Later is besloten om enkel drie kolommen te behouden in deze dataset. Daarom missen er heel wat kolommen uit de oorspronkelijke code met het bestand. De code om deze kolommen eruit te halen is te vinden in het hoofdstuk preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Film            object\n",
       "Omschrijving    object\n",
       "Genres          object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Film</th>\n",
       "      <th>Omschrijving</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>Over the course of several years, two convicts...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>Don Vito Corleone, head of a mafia family, dec...</td>\n",
       "      <td>Crime, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>When the menace known as the Joker wreaks havo...</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>In German-occupied Poland during World War II,...</td>\n",
       "      <td>Biography, Drama, History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>Gandalf and Aragorn lead the World of Men agai...</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>When Marnie Was There</td>\n",
       "      <td>Due to 12-year-old Anna's asthma, she's sent t...</td>\n",
       "      <td>Animation, Drama, Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Control</td>\n",
       "      <td>A profile of Ian Curtis, the enigmatic singer ...</td>\n",
       "      <td>Biography, Drama, Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Philomena</td>\n",
       "      <td>A world-weary political journalist picks up th...</td>\n",
       "      <td>Biography, Comedy, Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Shine</td>\n",
       "      <td>Pianist David Helfgott, driven by his father a...</td>\n",
       "      <td>Biography, Drama, Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Cell 211</td>\n",
       "      <td>The story of two men on different sides of a p...</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Film  \\\n",
       "0                         The Shawshank Redemption   \n",
       "1                                    The Godfather   \n",
       "2                                  The Dark Knight   \n",
       "3                                 Schindler's List   \n",
       "4    The Lord of the Rings: The Return of the King   \n",
       "..                                             ...   \n",
       "995                          When Marnie Was There   \n",
       "996                                        Control   \n",
       "997                                      Philomena   \n",
       "998                                          Shine   \n",
       "999                                       Cell 211   \n",
       "\n",
       "                                          Omschrijving  \\\n",
       "0    Over the course of several years, two convicts...   \n",
       "1    Don Vito Corleone, head of a mafia family, dec...   \n",
       "2    When the menace known as the Joker wreaks havo...   \n",
       "3    In German-occupied Poland during World War II,...   \n",
       "4    Gandalf and Aragorn lead the World of Men agai...   \n",
       "..                                                 ...   \n",
       "995  Due to 12-year-old Anna's asthma, she's sent t...   \n",
       "996  A profile of Ian Curtis, the enigmatic singer ...   \n",
       "997  A world-weary political journalist picks up th...   \n",
       "998  Pianist David Helfgott, driven by his father a...   \n",
       "999  The story of two men on different sides of a p...   \n",
       "\n",
       "                        Genres  \n",
       "0                        Drama  \n",
       "1                 Crime, Drama  \n",
       "2         Action, Crime, Drama  \n",
       "3    Biography, Drama, History  \n",
       "4     Action, Adventure, Drama  \n",
       "..                         ...  \n",
       "995   Animation, Drama, Family  \n",
       "996    Biography, Drama, Music  \n",
       "997   Biography, Comedy, Drama  \n",
       "998    Biography, Drama, Music  \n",
       "999       Action, Crime, Drama  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inladen van IMDb Data\n",
    "webscraper = pd.read_csv('IMDb_data.csv')\n",
    "\n",
    "# Tonen data\n",
    "display(webscraper.dtypes)\n",
    "display(webscraper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het dataframe ziet er inmiddels anders uit dan dat in de code staat beschreven. De reden hiervoor is dat de uiteindelijk onnodige kolommen zijn verwijderd en vervolgens opnieuw het csv is aangemaakt in het hoofdstuk preprocessing. Door een klein overzichtsfoutje heeft het nieuwe csv bestand dezelfde naam gekregen als de oude en is de oude dus overschreven. Dit is door middel van deze code gebeurt:\n",
    "\n",
    "```py\n",
    "# Lijst voor kolommen om te behouden\n",
    "cols_to_keep = ['Titel', 'Beschrijving', 'Genre']\n",
    "\n",
    "# Alleen behouden van de nodige kolommen\n",
    "films = films[cols_to_keep]\n",
    "\n",
    "# Opslaan van aanpassingen in CSV\n",
    "films.to_csv('IMDb_data.csv', index=False)\n",
    "```\n",
    "Het dataframe zal in deze staat ook gebruikt worden in de pipeline, dus daarvoor is er niks veranderd.\n",
    "\n",
    "[Terug naar Inhoudsopgave](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Database: Movie Summaries</div>\n",
    "    <a name='db'></a>\n",
    "</div>\n",
    "\n",
    "Voor het Database onderdeel van de opgave, is er gebruik gemaakt van een online downloadbare bron genaamd de Movie Summary Corpus. Deze databron bevat verschillende informatie van ongeveer 42000 films. Er staat informatie over de verschillende karakters in de films, een uitgebreide omschrijving van het plot en metadata over de film. Voor dit onderzoek zal de data over de karakters niet nodig zijn en dus zal deze niet worden ingeladen. De onderstaande stukken uitleg zijn voor de data die wij gaan gebruiken. Met dank aan de README.txt die bij de download van de data zat, is het gemakkelijker om de data en de structuur te begrijpen. Voor het inladen van elk bestand is de README gebruikt om de kolomnamen aan te maken en de data op de juiste manier in te laden.\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:20px; font-weight:bold;\">Bestand: plot_summaries.txt</div>\n",
    "    <a name='db'></a>\n",
    "</div>\n",
    "\n",
    "Door middel van pd.read_csv is het mogelijk om text bestanden in te lezen. Bij het bekijken van het tekst bestand werd duidelijk dat de scheiding van kolommen is aangegeven door een tab. Verder is de README informatie gebruikt om de kolomnamen te maken:\n",
    "- Plot summaries of 42,306 movies extracted from the November 2, 2012 dump of English-language Wikipedia.  Each line contains the Wikipedia movie ID (which indexes into movie.metadata.tsv) followed by the summary. (Gekopieerd van README.txt)\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:20px; font-weight:bold;\">Bestand: movie.metadata.tsv</div>\n",
    "</div>\n",
    "\n",
    "Ook bij dit tsv bestand kan er gebruik worden gemaakt van de pd.read_csv functie. Bij het lezen van de README is duidelijk neergezet hoe de structuur van dit bestand eruit ziet.\n",
    "\n",
    "Metadata for 81,741 movies, extracted from the Noverber 4, 2012 dump of Freebase.  Tab-separated; columns: (Gekopieerd van README.txt)\n",
    "\n",
    "1. Wikipedia movie ID\n",
    "2. Freebase movie ID\n",
    "3. Movie name\n",
    "4. Movie release date\n",
    "5. Movie box office revenue\n",
    "6. Movie runtime\n",
    "7. Movie languages (Freebase ID:name tuples)\n",
    "8. Movie countries (Freebase ID:name tuples)\n",
    "9. Movie genres (Freebase ID:name tuples)\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:20px; font-weight:bold;\">Data inladen naar database</div>\n",
    "</div>\n",
    "\n",
    "Om de data in te kunnen lezen, wordt er gebruik gemaakt van een database. Deze database zal worden aangemaakt door de corpus van het internet te downloaden, om deze vervolgens in een database in te laden. Deze taken worden gedaan met behulp van verschillende libaries, met name urllib en sqlite3. Om al deze stappen uit te voeren worden er eerst een aantal functies aangemaakt. Elke functie heeft zijn eigen doel en samen geven ze een gestreamlinede weg naar het maken van de database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloaden_en_extraheren(url, folder):\n",
    "    \"\"\"\n",
    "    Deze functie download een gecomprimeerd archief van de\n",
    "    opgegeven URL en extraheerd de data naar een opgegeven map.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    url : str\n",
    "        De URL van het te downloaden archief.\n",
    "\n",
    "    folder : str\n",
    "        Het pad naar de doelmap waarin de\n",
    "        bestanden worden geëxtraheerd.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Openen van de URL en lezen van de response\n",
    "    response = urllib.request.urlopen(url)\n",
    "    tar_data = BytesIO(response.read())\n",
    "\n",
    "    # Downloaden en extraheren van de bestanden\n",
    "    with tarfile.open(fileobj=tar_data, mode='r:gz') as tar:\n",
    "        tar.extractall(path=folder)\n",
    "\n",
    "def dataframe_naar_database(df, tabel_naam, db_loc):\n",
    "    \"\"\"\n",
    "    Overzetten van een Pandas DataFrame naar een\n",
    "    SQLite-database tabel.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Het DataFrame dat moet worden overgezet.\n",
    "\n",
    "    tabel_naam : str\n",
    "        De naam van de tabel in de database.\n",
    "\n",
    "    db_loc : str\n",
    "        Het pad naar de SQLite-database.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Verbinden met de database\n",
    "    conn = sqlite3.connect(db_loc)\n",
    "\n",
    "    # Aanmaken van de tabel\n",
    "    df.to_sql(name=tabel_naam, con=conn, if_exists='replace', index=False)\n",
    "\n",
    "    # Pushen van verandering naar Database en stoppen connectie\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def query_exe(db_loc, query):\n",
    "    \"\"\"\n",
    "    Uitvoeren van een SQL-query op de opgegeven SQLite-database\n",
    "    en de resultaten omzetten naar een Pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    db_loc : str\n",
    "        Het pad naar de SQLite-database.\n",
    "\n",
    "    query : str\n",
    "        De SQL-query die moet worden uitgevoerd.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Het resultaat van de query als een DataFrame.\n",
    "    \"\"\"\n",
    "    # Verbinden met de database\n",
    "    conn = sqlite3.connect(db_loc)\n",
    "\n",
    "    # Query inlezen tot dataframe\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "\n",
    "    # Sluiten van de connectie met database\n",
    "    conn.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de functies aangemaakt, kunnen we de nodige parameters definieeren om de data te downloaden en in te laden in de database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL download\n",
    "url = \"http://www.cs.cmu.edu/~ark/personas/data/MovieSummaries.tar.gz\"\n",
    "\n",
    "# Folder path\n",
    "folder = \"MovieSummaries\"\n",
    "\n",
    "# Database naam\n",
    "db_loc = 'movie_database.db'\n",
    "\n",
    "# Kolommen van de data\n",
    "kolommen = {\n",
    "    \"movie.metadata\": ['Wikipedia_ID', 'Freebase_ID', 'Titel',\n",
    "                       'Release_date', 'Box_office', 'Lengte',\n",
    "                       'Talen', 'Landen', 'Genre'],\n",
    "    \"character.metadata\": ['Wikipedia_ID', 'Freebase_ID', 'Release_date',\n",
    "                           'Char_Name', 'Actor_DoB', 'Actor_gender', 'Actor_h',\n",
    "                           'Actor_eth', 'Actor_Name', 'Actor_age',\n",
    "                           'Freebase_map_ID', 'Freebase_ch_ID', 'Freebase_ac_ID'],\n",
    "    \"plot_summaries\": ['Wikipedia_ID', 'Beschrijving'],\n",
    "    \"name.clusters\": ['Name', 'Freebase_ID'],\n",
    "    \"tvtropes.clusters\": ['Trope', 'Character_Data']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met gebruik van deze vier parameters is het mogelijk om de nodige functies voor het downloaden van de data en het inladen in de database uit te gaan voeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processen van TSV bestand: MovieSummaries\\MovieSummaries\\character.metadata.tsv\n",
      "Tabel 'character.metadata' is toegevoegd\n",
      "Processen van TSV bestand: MovieSummaries\\MovieSummaries\\movie.metadata.tsv\n",
      "Tabel 'movie.metadata' is toegevoegd\n",
      "Processen van TXT bestand: MovieSummaries\\MovieSummaries\\name.clusters.txt\n",
      "Tabel 'name.clusters' is toegevoegd\n",
      "Processen van TXT bestand: MovieSummaries\\MovieSummaries\\plot_summaries.txt\n",
      "Tabel 'plot_summaries' is toegevoegd\n",
      "Processen van TXT bestand: MovieSummaries\\MovieSummaries\\tvtropes.clusters.txt\n",
      "Tabel 'tvtropes.clusters' is toegevoegd\n"
     ]
    }
   ],
   "source": [
    "# Uitvoeren van de download en extract stap\n",
    "downloaden_en_extraheren(url, folder)\n",
    "\n",
    "# Loopen over de folder met geextraheerde data\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        # Aanmaken van bestand locatie, type en de tabel naam\n",
    "        file_path = os.path.join(root, file)\n",
    "        file_type = 'tsv' if file.endswith(\".tsv\") else 'txt'\n",
    "        tabel_naam = os.path.splitext(file)[0]\n",
    "\n",
    "        # Excluderen van README.txt\n",
    "        if file != \"README.txt\":\n",
    "            print(f\"Processen van {file_type.upper()} bestand: {file_path}\")\n",
    "\n",
    "            # Aangeven welke kolommen worden gebruikt\n",
    "            custom_kols = kolommen.get(tabel_naam, None)\n",
    "\n",
    "            # Aanmaken van dataframe\n",
    "            df = pd.read_csv(file_path, sep='\\t', names=custom_kols)\n",
    "\n",
    "            # Dataframe transporteren naar database\n",
    "            dataframe_naar_database(df, tabel_naam, db_loc)\n",
    "            print(f\"Tabel '{tabel_naam}' is toegevoegd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu alle data als tabel is toegevoegd in de database, worden er een paar queries uitgevoerd. Op deze manier is het aan te tonen dat de code heeft gewerkt. De eerste is om aan te tonen dat het werkt, de tweede is het dataframe dat uiteindelijk gebruikt zal worden. Dit tweede dataframe zal vervolgens ook worden gebruikt om te kijken welke stappen van preprocessing en feature engineering nodig zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia_ID</th>\n",
       "      <th>Titel</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81736</th>\n",
       "      <td>35228177</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81737</th>\n",
       "      <td>34980460</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81738</th>\n",
       "      <td>9971909</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>{\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81739</th>\n",
       "      <td>913762</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81740</th>\n",
       "      <td>12476867</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81741 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia_ID                                              Titel  \\\n",
       "0            975900                                     Ghosts of Mars   \n",
       "1           3196793  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "2          28463795                                        Brun bitter   \n",
       "3           9363483                                   White Of The Eye   \n",
       "4            261236                                  A Woman in Flames   \n",
       "...             ...                                                ...   \n",
       "81736      35228177                           Mermaids: The Body Found   \n",
       "81737      34980460                                            Knuckle   \n",
       "81738       9971909                                  Another Nice Mess   \n",
       "81739        913762  The Super Dimension Fortress Macross II: Lover...   \n",
       "81740      12476867                                            Spliced   \n",
       "\n",
       "                                                   Genre  \n",
       "0      {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1      {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  \n",
       "2      {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  \n",
       "3      {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "4                                {\"/m/07s9rl0\": \"Drama\"}  \n",
       "...                                                  ...  \n",
       "81736                            {\"/m/07s9rl0\": \"Drama\"}  \n",
       "81737  {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...  \n",
       "81738       {\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}  \n",
       "81739  {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...  \n",
       "81740  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  \n",
       "\n",
       "[81741 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aanmaken van query\n",
    "query = \"\"\"\n",
    "    SELECT Wikipedia_ID,\n",
    "           Titel,\n",
    "           Genre\n",
    "        FROM 'movie.metadata'\n",
    "\"\"\"\n",
    "\n",
    "# Aanmaken van dataframe door query in te lezen\n",
    "df_test = query_exe(db_loc, query)\n",
    "\n",
    "# Tonen van dataframe\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Beschrijving</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>{\"/m/0hqxf\": \"Family Film\", \"/m/01hmnh\": \"Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little city</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>{\"/m/06cvj\": \"Romantic comedy\", \"/m/0hj3n0w\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42199</th>\n",
       "      <td>The Ghost Train</td>\n",
       "      <td>{{plot}} The film opens with a Great Western e...</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/01jfsb\": \"Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42200</th>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>Two former National Oceanic Atmospheric Admini...</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42201</th>\n",
       "      <td>Knuckle</td>\n",
       "      <td>{{No plot}} This film follows 12 years in the ...</td>\n",
       "      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42202</th>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>The story takes place in the year 2092,The Sup...</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42203</th>\n",
       "      <td>Spliced</td>\n",
       "      <td>The movie is about a teenage girl who loves ho...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42204 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Titel  \\\n",
       "0                                         Ghosts of Mars   \n",
       "1                                       White Of The Eye   \n",
       "2                                      A Woman in Flames   \n",
       "3                              The Sorcerer's Apprentice   \n",
       "4                                            Little city   \n",
       "...                                                  ...   \n",
       "42199                                    The Ghost Train   \n",
       "42200                           Mermaids: The Body Found   \n",
       "42201                                            Knuckle   \n",
       "42202  The Super Dimension Fortress Macross II: Lover...   \n",
       "42203                                            Spliced   \n",
       "\n",
       "                                            Beschrijving  \\\n",
       "0      Set in the second half of the 22nd century, th...   \n",
       "1      A series of murders of rich young women throug...   \n",
       "2      Eva, an upper class housewife, becomes frustra...   \n",
       "3      Every hundred years, the evil Morgana  returns...   \n",
       "4      Adam, a San Francisco-based artist who works a...   \n",
       "...                                                  ...   \n",
       "42199  {{plot}} The film opens with a Great Western e...   \n",
       "42200  Two former National Oceanic Atmospheric Admini...   \n",
       "42201  {{No plot}} This film follows 12 years in the ...   \n",
       "42202  The story takes place in the year 2092,The Sup...   \n",
       "42203  The movie is about a teenage girl who loves ho...   \n",
       "\n",
       "                                                   Genre  \n",
       "0      {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1      {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "2                                {\"/m/07s9rl0\": \"Drama\"}  \n",
       "3      {\"/m/0hqxf\": \"Family Film\", \"/m/01hmnh\": \"Fant...  \n",
       "4      {\"/m/06cvj\": \"Romantic comedy\", \"/m/0hj3n0w\": ...  \n",
       "...                                                  ...  \n",
       "42199  {\"/m/0lsxr\": \"Crime Fiction\", \"/m/01jfsb\": \"Th...  \n",
       "42200                            {\"/m/07s9rl0\": \"Drama\"}  \n",
       "42201  {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...  \n",
       "42202  {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...  \n",
       "42203  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  \n",
       "\n",
       "[42204 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aanmaken van query\n",
    "query = \"\"\"\n",
    "    SELECT mm.Titel,\n",
    "           ps.Beschrijving,\n",
    "           mm.Genre\n",
    "    FROM 'movie.metadata' AS mm\n",
    "        \n",
    "    JOIN 'plot_summaries' AS ps\n",
    "        ON mm.Wikipedia_ID = ps.Wikipedia_ID\n",
    "\"\"\"\n",
    "\n",
    "# Aanmaken van dataframe door query in te lezen\n",
    "database = query_exe(db_loc, query)\n",
    "\n",
    "# Tonen van dataframe\n",
    "display(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Terug naar Inhoudsopgave](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">API</div>\n",
    "    <a name='api'></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voor het API onderdeel van de opgave, is er gebruik gemaakt van een gratis move api van de website Rapid api. Deze api bevat meer dan 9 miljoen verschillende titles van films, series en afleveringen. De titels worden weekelijks geupdate en de ratings en afleveringen worden dagelijks bijgewerkt. In de api staat informatie over de films en series waaronder de cast, de awards die gewonnen zijn, het jaar dat het uitkwam, de rating (van de IMDB-website), het genre en een korte omschrijving van de film/serie. Wij gebruiken alleen de titel, het genre en een korte omschrijving van de film dus hier beneden zie je de code over hoe wij deze uit de api data hebben gehaald."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoeren van API_URL\n",
    "url = \"https://moviesdatabase.p.rapidapi.com/titles\"\n",
    "\n",
    "# Invoeren van query parameters\n",
    "querystring = {\"limit\":\"50\", \"info\":\"base_info\"}\n",
    "\n",
    "# Invoeren van headers voor de RapidAPI\n",
    "headers = {\n",
    "\t\"X-RapidAPI-Key\": \"862efd2e3dmsh364685e1c50acb8p153999jsnd3c8b4543ef9\",\n",
    "\t\"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Beschrijving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les blanchisseuses</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>This lost film presumably features women washi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dessinateur: Von Bismark</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>This lost film featured a talented sketch arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boxing Match; or, Glove Contest</td>\n",
       "      <td>[Short, Sport]</td>\n",
       "      <td>Stage boxing match between Sergeant-Instructor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plus fort que le maître</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>Little is known about this lost film, the thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cripple Creek Bar-Room Scene</td>\n",
       "      <td>[Western, Short]</td>\n",
       "      <td>A vignette of a barroom/liquor-store in the We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Séance de prestidigitation</td>\n",
       "      <td>[Short]</td>\n",
       "      <td>Boognish the goddemon Wants your soul to perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>L'hallucination de l'alchimiste</td>\n",
       "      <td>[Short, Fantasy, Horror]</td>\n",
       "      <td>Misidentified as Alchimiste Parafaragaramus ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Une partie de cartes</td>\n",
       "      <td>[Short, Biography]</td>\n",
       "      <td>In what is considered to be the first remake i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Escamotage d'une dame au théâtre Robert Houdin</td>\n",
       "      <td>[Short, Horror]</td>\n",
       "      <td>As an elegant maestro of mirage and delusion d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Campement de bohémiens</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>Very little is known of this lost film; accord...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>[Animation, Comedy, Short, Romance]</td>\n",
       "      <td>One night, Arlequin come to see his lover Colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Rough Sea at Dover</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>The sea is quite rough, and at Dover a series ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The Miller and the Sweep</td>\n",
       "      <td>[Comedy, Short]</td>\n",
       "      <td>In front of a flour mill, two men fight. One i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The Miser's Doom</td>\n",
       "      <td>[Short, Horror]</td>\n",
       "      <td>A miser dies of shock when the ghost of a poor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The Burglar on the Roof</td>\n",
       "      <td>[Short, Crime]</td>\n",
       "      <td>There is a burglar on the rooftop of a Manhatt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Baignade en mer</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>Several little boys run along a pier, then jum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Le débarquement du congrès de photographie à Lyon</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>The photographers who need to participate in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Démolition d'un mur</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>Auguste Lumière directs four workers in the de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Départ de Jérusalem en chemin de fer</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>A train is leaving a railway station at the ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Llegada de un tren a la estación de ferrocarri...</td>\n",
       "      <td>[Documentary, Short]</td>\n",
       "      <td>Short documentary where a train arrives at the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Titel  \\\n",
       "1                                  Les blanchisseuses   \n",
       "2                            Dessinateur: Von Bismark   \n",
       "3                     Boxing Match; or, Glove Contest   \n",
       "4                             Plus fort que le maître   \n",
       "7                        Cripple Creek Bar-Room Scene   \n",
       "11                         Séance de prestidigitation   \n",
       "15                    L'hallucination de l'alchimiste   \n",
       "16                               Une partie de cartes   \n",
       "21     Escamotage d'une dame au théâtre Robert Houdin   \n",
       "22                             Campement de bohémiens   \n",
       "23                                     Pauvre Pierrot   \n",
       "24                                 Rough Sea at Dover   \n",
       "27                           The Miller and the Sweep   \n",
       "29                                   The Miser's Doom   \n",
       "30                            The Burglar on the Roof   \n",
       "33                                    Baignade en mer   \n",
       "36  Le débarquement du congrès de photographie à Lyon   \n",
       "39                                Démolition d'un mur   \n",
       "40               Départ de Jérusalem en chemin de fer   \n",
       "43  Llegada de un tren a la estación de ferrocarri...   \n",
       "\n",
       "                                  Genre  \\\n",
       "1                               [Short]   \n",
       "2                               [Short]   \n",
       "3                        [Short, Sport]   \n",
       "4                               [Short]   \n",
       "7                      [Western, Short]   \n",
       "11                              [Short]   \n",
       "15             [Short, Fantasy, Horror]   \n",
       "16                   [Short, Biography]   \n",
       "21                      [Short, Horror]   \n",
       "22                 [Documentary, Short]   \n",
       "23  [Animation, Comedy, Short, Romance]   \n",
       "24                 [Documentary, Short]   \n",
       "27                      [Comedy, Short]   \n",
       "29                      [Short, Horror]   \n",
       "30                       [Short, Crime]   \n",
       "33                 [Documentary, Short]   \n",
       "36                 [Documentary, Short]   \n",
       "39                 [Documentary, Short]   \n",
       "40                 [Documentary, Short]   \n",
       "43                 [Documentary, Short]   \n",
       "\n",
       "                                         Beschrijving  \n",
       "1   This lost film presumably features women washi...  \n",
       "2   This lost film featured a talented sketch arti...  \n",
       "3   Stage boxing match between Sergeant-Instructor...  \n",
       "4   Little is known about this lost film, the thir...  \n",
       "7   A vignette of a barroom/liquor-store in the We...  \n",
       "11  Boognish the goddemon Wants your soul to perfo...  \n",
       "15  Misidentified as Alchimiste Parafaragaramus ou...  \n",
       "16  In what is considered to be the first remake i...  \n",
       "21  As an elegant maestro of mirage and delusion d...  \n",
       "22  Very little is known of this lost film; accord...  \n",
       "23  One night, Arlequin come to see his lover Colo...  \n",
       "24  The sea is quite rough, and at Dover a series ...  \n",
       "27  In front of a flour mill, two men fight. One i...  \n",
       "29  A miser dies of shock when the ghost of a poor...  \n",
       "30  There is a burglar on the rooftop of a Manhatt...  \n",
       "33  Several little boys run along a pier, then jum...  \n",
       "36  The photographers who need to participate in t...  \n",
       "39  Auguste Lumière directs four workers in the de...  \n",
       "40  A train is leaving a railway station at the ou...  \n",
       "43  Short documentary where a train arrives at the...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ophalen van response API\n",
    "response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "# Aanmaken lijst voor API-Data\n",
    "resultaten = []\n",
    "\n",
    "# Itereer over elk resultaat in de 'results' lijst van de JSON-respons\n",
    "for resultaat in response.json()['results']:\n",
    "    # Haal de benodigde velden op\n",
    "    titel = resultaat['titleText']['text'] if 'titleText' in resultaat else np.nan\n",
    "    genres = [genre['text'] for genre in resultaat['genres']['genres']] if 'genres' in resultaat else np.nan\n",
    "    plot = resultaat['plot']['plotText']['plainText'] if 'plot' in resultaat and resultaat['plot'] and 'plotText' in resultaat['plot'] else np.nan\n",
    "\n",
    "    # Voeg de resultaten toe aan de lijst\n",
    "    resultaten.append({\n",
    "        'Titel': titel,\n",
    "        'Genre': genres,\n",
    "        'Beschrijving': plot\n",
    "    })\n",
    "\n",
    "# Aanmaken dataframe op basis van opgehaalde data\n",
    "df_yes = pd.DataFrame(resultaten)\n",
    "\n",
    "# verwijder de missende waardes\n",
    "df_yes.dropna(subset=['Titel', 'Genre', 'Beschrijving'], inplace=True)\n",
    "\n",
    "# Toon de DataFrame\n",
    "display(df_yes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Beschrijving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les haleurs de bateaux</td>\n",
       "      <td>Documentary, Short</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les blanchisseuses</td>\n",
       "      <td>Short</td>\n",
       "      <td>This lost film presumably features women washi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dessinateur: Von Bismark</td>\n",
       "      <td>Short</td>\n",
       "      <td>This lost film featured a talented sketch arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boxing Match; or, Glove Contest</td>\n",
       "      <td>Short, Sport</td>\n",
       "      <td>Stage boxing match between Sergeant-Instructor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plus fort que le maître</td>\n",
       "      <td>Short</td>\n",
       "      <td>Little is known about this lost film, the thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Il mercante di Venezia</td>\n",
       "      <td>Short, Drama</td>\n",
       "      <td>With a friend desperate for money, a merchant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Julius Caesar</td>\n",
       "      <td>Short, Crime, History</td>\n",
       "      <td>Roman Senators conspire to assassinate their r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The Ranchman's Feud</td>\n",
       "      <td>Short, Western</td>\n",
       "      <td>Hiram Matthews, a western ranchman, owns an ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The Thread of Destiny</td>\n",
       "      <td>Romance, Short</td>\n",
       "      <td>Little Myrtle, the orphan girl of San Gabriel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>As in a Looking Glass</td>\n",
       "      <td>Short, Drama</td>\n",
       "      <td>A father's drinking leads him to neglect his f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Titel                  Genre  \\\n",
       "0             Les haleurs de bateaux     Documentary, Short   \n",
       "1                 Les blanchisseuses                  Short   \n",
       "2           Dessinateur: Von Bismark                  Short   \n",
       "3    Boxing Match; or, Glove Contest           Short, Sport   \n",
       "4            Plus fort que le maître                  Short   \n",
       "..                               ...                    ...   \n",
       "995           Il mercante di Venezia           Short, Drama   \n",
       "996                    Julius Caesar  Short, Crime, History   \n",
       "997              The Ranchman's Feud         Short, Western   \n",
       "998            The Thread of Destiny         Romance, Short   \n",
       "999            As in a Looking Glass           Short, Drama   \n",
       "\n",
       "                                          Beschrijving  \n",
       "0                                                  NaN  \n",
       "1    This lost film presumably features women washi...  \n",
       "2    This lost film featured a talented sketch arti...  \n",
       "3    Stage boxing match between Sergeant-Instructor...  \n",
       "4    Little is known about this lost film, the thir...  \n",
       "..                                                 ...  \n",
       "995  With a friend desperate for money, a merchant ...  \n",
       "996  Roman Senators conspire to assassinate their r...  \n",
       "997  Hiram Matthews, a western ranchman, owns an ap...  \n",
       "998  Little Myrtle, the orphan girl of San Gabriel,...  \n",
       "999  A father's drinking leads him to neglect his f...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://moviesdatabase.p.rapidapi.com/titles\"\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"862efd2e3dmsh364685e1c50acb8p153999jsnd3c8b4543ef9\",\n",
    "    \"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "\n",
    "resultaten = []\n",
    "\n",
    "# Itereer over de paginanummers\n",
    "for page_number in range(1, 21):\n",
    "    \n",
    "    querystring = {\n",
    "        \"page\": str(page_number),\n",
    "        \"info\": \"base_info\",\n",
    "        \"limit\": \"50\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    # Itereer over elk resultaat in de 'results' lijst van de JSON-respons\n",
    "    for resultaat in response.json()['results']:\n",
    "        # Haal de benodigde velden op\n",
    "        titel = resultaat['titleText']['text'] if 'titleText' in resultaat else np.nan\n",
    "\n",
    "        # Check if 'genres' is present and not None\n",
    "        if 'genres' in resultaat and resultaat['genres']:\n",
    "            # Use ', '.join() to convert the list of genres into a comma-separated string\n",
    "            genres = ', '.join([genre['text'] for genre in resultaat['genres']['genres']])\n",
    "        else:\n",
    "            genres = np.nan\n",
    "\n",
    "        plot = resultaat['plot']['plotText']['plainText'] if 'plot' in resultaat and resultaat['plot'] and 'plotText' in resultaat['plot'] else np.nan\n",
    "\n",
    "        # Voeg de resultaten toe aan de lijst\n",
    "        resultaten.append({\n",
    "            'Titel': titel,\n",
    "            'Genre': genres,\n",
    "            'Beschrijving': plot\n",
    "        })\n",
    "\n",
    "api = pd.DataFrame(resultaten)\n",
    "\n",
    "# Toon de DataFrame\n",
    "display(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Beschrijving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Les haleurs de bateaux</td>\n",
       "      <td>Documentary, Short</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les blanchisseuses</td>\n",
       "      <td>Short</td>\n",
       "      <td>This lost film presumably features women washi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dessinateur: Von Bismark</td>\n",
       "      <td>Short</td>\n",
       "      <td>This lost film featured a talented sketch arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boxing Match; or, Glove Contest</td>\n",
       "      <td>Short, Sport</td>\n",
       "      <td>Stage boxing match between Sergeant-Instructor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plus fort que le maître</td>\n",
       "      <td>Short</td>\n",
       "      <td>Little is known about this lost film, the thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Il mercante di Venezia</td>\n",
       "      <td>Short, Drama</td>\n",
       "      <td>With a friend desperate for money, a merchant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Julius Caesar</td>\n",
       "      <td>Short, Crime, History</td>\n",
       "      <td>Roman Senators conspire to assassinate their r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The Ranchman's Feud</td>\n",
       "      <td>Short, Western</td>\n",
       "      <td>Hiram Matthews, a western ranchman, owns an ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The Thread of Destiny</td>\n",
       "      <td>Romance, Short</td>\n",
       "      <td>Little Myrtle, the orphan girl of San Gabriel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>As in a Looking Glass</td>\n",
       "      <td>Short, Drama</td>\n",
       "      <td>A father's drinking leads him to neglect his f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Titel                  Genre  \\\n",
       "0             Les haleurs de bateaux     Documentary, Short   \n",
       "1                 Les blanchisseuses                  Short   \n",
       "2           Dessinateur: Von Bismark                  Short   \n",
       "3    Boxing Match; or, Glove Contest           Short, Sport   \n",
       "4            Plus fort que le maître                  Short   \n",
       "..                               ...                    ...   \n",
       "995           Il mercante di Venezia           Short, Drama   \n",
       "996                    Julius Caesar  Short, Crime, History   \n",
       "997              The Ranchman's Feud         Short, Western   \n",
       "998            The Thread of Destiny         Romance, Short   \n",
       "999            As in a Looking Glass           Short, Drama   \n",
       "\n",
       "                                          Beschrijving  \n",
       "0                                                  NaN  \n",
       "1    This lost film presumably features women washi...  \n",
       "2    This lost film featured a talented sketch arti...  \n",
       "3    Stage boxing match between Sergeant-Instructor...  \n",
       "4    Little is known about this lost film, the thir...  \n",
       "..                                                 ...  \n",
       "995  With a friend desperate for money, a merchant ...  \n",
       "996  Roman Senators conspire to assassinate their r...  \n",
       "997  Hiram Matthews, a western ranchman, owns an ap...  \n",
       "998  Little Myrtle, the orphan girl of San Gabriel,...  \n",
       "999  A father's drinking leads him to neglect his f...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://moviesdatabase.p.rapidapi.com/titles\"\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"862efd2e3dmsh364685e1c50acb8p153999jsnd3c8b4543ef9\",\n",
    "    \"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "resultaten = []\n",
    "\n",
    "# Itereer over de paginanummers\n",
    "for page_number in range(1, 21):\n",
    "    \n",
    "    querystring = {\n",
    "        \"page\": str(page_number),\n",
    "        \"info\": \"base_info\",\n",
    "        \"limit\": \"50\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Itereer over elk resultaat in de 'results' lijst van de JSON-respons\n",
    "        json_response = response.json()\n",
    "        if 'results' in json_response:\n",
    "            for resultaat in json_response['results']:\n",
    "                # Haal de benodigde velden op\n",
    "                titel = resultaat['titleText']['text'] if 'titleText' in resultaat else np.nan\n",
    "\n",
    "                # Check if 'genres' is present and not None\n",
    "                if 'genres' in resultaat and resultaat['genres']:\n",
    "                    # Use ', '.join() to convert the list of genres into a comma-separated string\n",
    "                    genres = ', '.join([genre['text'] for genre in resultaat['genres']['genres']])\n",
    "                else:\n",
    "                    genres = np.nan\n",
    "\n",
    "                plot = resultaat['plot']['plotText']['plainText'] if 'plot' in resultaat and resultaat['plot'] and 'plotText' in resultaat['plot'] else np.nan\n",
    "\n",
    "                # Voeg de resultaten toe aan de lijst\n",
    "                resultaten.append({\n",
    "                    'Titel': titel,\n",
    "                    'Genre': genres,\n",
    "                    'Beschrijving': plot\n",
    "                })\n",
    "        else:\n",
    "            print(f\"Error: 'results' not found in JSON response for page {page_number}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Request failed with status code {response.status_code}\")\n",
    "\n",
    "# Creëer DataFrame\n",
    "api = pd.DataFrame(resultaten)\n",
    "\n",
    "# Toon de DataFrame\n",
    "display(api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Terug naar Inhoudsopgave](#begin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Preprocessing en Feature Engineering</div>\n",
    "    <a name='tr'></a>\n",
    "</div>\n",
    "\n",
    "Om te kunnen werken met de ingeladen data is het noodzakelijk dat er toepassingen op worden uitgevoerd. De eerste vorm van toepassingen heet preprocessing. Deze stap is verantwoordelijk voor het volledig opschonen van de data. De tweede vorm heet Feature engineering. Deze vorm van toepassingen slaan op het bruikbaar maken van de data voor Machine Learning. Hierbij moeten er vaak nieuwe kolommen worden aangemaakt, of moeten oude kolommen worden herschreven. In deze sectie van het notebook gaan we kijken naar welke transformaties de data nodig zal hebben om bruikbaar te zijn voor Machine Learning.\n",
    "\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:20px; font-weight:bold;\">Preprocessing</div>\n",
    "</div>\n",
    "\n",
    "Omdat veel data vanuit ruwe bronnen niet correct of compleet is, is het nodig om de data waar nodig aan te passen. Deze eerste aanpassingen zijn de stappen voor preprocessing. In dit process is het gebruikelijk dat de data volledig wordt opgeschoond en dat er eventuele technieken worden gebruikt om bepaalde data typen beter bruikbaar te maken. Doorgaande dit gedeelte van het notebook worden verschillende technieken van preprocessing gebruikt om de tekst op de juiste manier voor te bereiden op de volgende stappen. Om hiermee te beginnen zal er worden gekeken naar missende waarden in onze datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_info(df):\n",
    "    \"\"\"\n",
    "    Deze functie maakt een dataframe waarbij er een soort omschrijving komt\n",
    "    over de data in elk dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Het dataframe waarbij de kolommen worden bekeken\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    info : pd.DataFrame\n",
    "        Een dataframe met de volgende informatie:\n",
    "            - Aantal missende waarden\n",
    "            - Percentage missende waarden\n",
    "            - Aantal nulwaarden voor numerieke kolommen\n",
    "            - Type data (numeriek of categorie)\n",
    "            - Hoeveelheid categorieen\n",
    "    \"\"\"\n",
    "    # Maak een dataframe met missende waarden\n",
    "    info = pd.DataFrame(df.isnull().sum(), columns=['Missende_waarden'])\n",
    "\n",
    "    # Voeg een kolom toe met percentage missende waarden\n",
    "    info['Perc_missend'] = round(info['Missende_waarden'] / len(df) * 100, 2)\n",
    "\n",
    "    # Voeg een kolom toe voor data type\n",
    "    types = []\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            types.append('Numeriek')\n",
    "        else:\n",
    "            types.append('Categorie')\n",
    "    info['Type'] = types\n",
    "\n",
    "    # Voeg een kolom toe met aantal nulwaarden\n",
    "    nulwaarden = []\n",
    "\n",
    "    # For-Loop om te kijken voor data type\n",
    "    for col in df.columns:\n",
    "        if np.issubdtype(df[col].dtype, np.number):\n",
    "            nulwaarden.append((df[col] == 0).sum())\n",
    "        else:\n",
    "            nulwaarden.append('-')\n",
    "    info['Nulwaarden'] = nulwaarden\n",
    "\n",
    "    # Voeg een kolom toe voor aantal categorieen\n",
    "    cat_aantal = []\n",
    "\n",
    "    # For-Loop om te kijken voor data type\n",
    "    for col in df.columns:\n",
    "        if info.loc[col, 'Type'] == 'Categorie':\n",
    "            cat_aantal.append(df[col].nunique())\n",
    "        else:\n",
    "            cat_aantal.append('-')\n",
    "    info['Aantal_Categorie'] = cat_aantal\n",
    "\n",
    "    return display(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aan de hand van deze functie kan er overzichtelijk worden gekeken naar de missende waarden van verschillende dataframes. Dit overzicht kan worden gebruikt om te bepalen wat we met de missende willen gaan doen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Titel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>39914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beschrijving</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>42196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>17851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Titel                        0           0.0  Categorie          -   \n",
       "Beschrijving                 0           0.0  Categorie          -   \n",
       "Genre                        0           0.0  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Titel                    39914  \n",
       "Beschrijving             42196  \n",
       "Genre                    17851  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Film</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omschrijving</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genres</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Film                         0           0.0  Categorie          -   \n",
       "Omschrijving                 0           0.0  Categorie          -   \n",
       "Genres                       0           0.0  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Film                       994  \n",
       "Omschrijving              1000  \n",
       "Genres                     194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Titel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>24</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beschrijving</th>\n",
       "      <td>378</td>\n",
       "      <td>37.8</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Titel                        0           0.0  Categorie          -   \n",
       "Genre                       24           2.4  Categorie          -   \n",
       "Beschrijving               378          37.8  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Titel                      985  \n",
       "Genre                      113  \n",
       "Beschrijving               610  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tonen van missende waarden per dataframe\n",
    "data_info(database)\n",
    "data_info(webscraper)\n",
    "data_info(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Er zijn gelukkig geen missende waarden aanwezig in de eerste twee dataframes. In het derde dataframe is dit wel zo. Om uiteindelijk tot nuttige voorspellingen te komen is het nodig om de beschrijving te gebruiken, om deze reden zullen de rijen met missende beschrijvingen worden verwijderd uit het dataframe. Hopelijk wordt hiermee ook het probleem van de missende genres opgelost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Titel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beschrijving</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Titel                        0          0.00  Categorie          -   \n",
       "Genre                        4          0.64  Categorie          -   \n",
       "Beschrijving                 0          0.00  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Titel                      615  \n",
       "Genre                      104  \n",
       "Beschrijving               610  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verwijderen van missende waarden in 'Beschrijving'\n",
    "api = api.dropna(subset=['Beschrijving'])\n",
    "\n",
    "# Tonen van status missende waarden\n",
    "data_info(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het eerder genoemde probleem van de genres is voor een groot deel verholpen, maar nog niet helemaal. Daarom zullen deze rijen ook worden gedropped, aangezien er geen missende waarden kunnen zitten in onze target kolom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Titel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beschrijving</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Titel                        0           0.0  Categorie          -   \n",
       "Genre                        0           0.0  Categorie          -   \n",
       "Beschrijving                 0           0.0  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Titel                      611  \n",
       "Genre                      104  \n",
       "Beschrijving               608  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Verwijderen van missende waarden in 'Genre'\n",
    "api = api.dropna(subset=['Genre'])\n",
    "\n",
    "# Tonen van status missende waarden\n",
    "data_info(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu deze aanpassingen zijn gemaakt, kunnen we naar de volgende stap gaan. Uit de string van genres moet alleen de eerste genoemde genre overblijven. Om dit te doen maken we gebruik van de split method. Deze method split de string in items gebaseerd op een parameter, in ons geval zal dit een komma zijn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eerste_genre(tekst, splitter):\n",
    "    \"\"\"\n",
    "    Deze functie maakt van een string aan genres een\n",
    "    enkel genre. Dit genre is degene die als eerste\n",
    "    in de string voorkomt.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tekst : str\n",
    "        Een string die de genres bevat, deze bevat voor elke\n",
    "        split hetzelfde te herkennen gedeelte. Bijv.: ', '.\n",
    "    \n",
    "    splitter : str\n",
    "        Het string gedeelte waarop de tekst wordt gesplitst.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split de tekst in delen aan de hang van ', '\n",
    "    genres = tekst.split(splitter)\n",
    "\n",
    "    # Selecteer het eerste genre\n",
    "    eerste_genre = genres[0]\n",
    "\n",
    "    return eerste_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aan de hand van deze functie zal het mogelijk zijn om alle strings in het dataframe in een keer te splitsen. Doordat we apply kunnen gebruiken in combinatie met lambda is deze handeling snel en effectief uit te voeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Genre'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Genre'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Toepassen van eerste genre functie\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m webscraper[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenre\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mwebscraper\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGenre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: eerste_genre(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tonen van de verandering\u001b[39;00m\n\u001b[0;32m      5\u001b[0m display(webscraper\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Genre'"
     ]
    }
   ],
   "source": [
    "# Toepassen van eerste genre functie\n",
    "webscraper['Genre'] = webscraper['Genre'].apply(lambda x: eerste_genre(x, ', '))\n",
    "\n",
    "# Tonen van de verandering\n",
    "display(webscraper.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu het eerste genre is bepaald voor de scraper data, kan er worden gewerkt aan de database data. Deze zit iets ingewikkelder in elkaar, om hieraan te werken is het belangrijk om eerst te kijken wat er precies aan de hand is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Beschrijving</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>{\"/m/0hqxf\": \"Family Film\", \"/m/01hmnh\": \"Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little city</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>{\"/m/06cvj\": \"Romantic comedy\", \"/m/0hj3n0w\": ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Titel  \\\n",
       "0             Ghosts of Mars   \n",
       "1           White Of The Eye   \n",
       "2          A Woman in Flames   \n",
       "3  The Sorcerer's Apprentice   \n",
       "4                Little city   \n",
       "\n",
       "                                        Beschrijving  \\\n",
       "0  Set in the second half of the 22nd century, th...   \n",
       "1  A series of murders of rich young women throug...   \n",
       "2  Eva, an upper class housewife, becomes frustra...   \n",
       "3  Every hundred years, the evil Morgana  returns...   \n",
       "4  Adam, a San Francisco-based artist who works a...   \n",
       "\n",
       "                                               Genre  \n",
       "0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  \n",
       "1  {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  \n",
       "2                            {\"/m/07s9rl0\": \"Drama\"}  \n",
       "3  {\"/m/0hqxf\": \"Family Film\", \"/m/01hmnh\": \"Fant...  \n",
       "4  {\"/m/06cvj\": \"Romantic comedy\", \"/m/0hj3n0w\": ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De kolom \"Titel\" heeft data-type <class 'str'>\n",
      "De kolom \"Beschrijving\" heeft data-type <class 'str'>\n",
      "De kolom \"Genre\" heeft data-type <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Tonen van de eerste vijf regels van df\n",
    "display(database.head())\n",
    "\n",
    "# Bekijken van type data in elke kolom\n",
    "for kolom in database.columns:\n",
    "    # Ophalen van type data\n",
    "    typ = type(database[kolom][0])\n",
    "    \n",
    "    # Tonen van kolom naam en type data\n",
    "    print(f'De kolom \"{kolom}\" heeft data-type {typ}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De kolommen die kunnen worden opgeschoond zijn de 'Film' kolom en de 'Genres' kolom. De 'Film' kolom zal later worden opgeschoond met een groter aantal tekst gebaseerde kolommen die zich in elke dataset bevind. De 'Genres' kolom zal worden opgeschoond door de values uit de dictionary te halen. Om dit te doen zullen we eerst de dictionaries goed moeten neerzetten, aangezien deze nu als string in het dataframe staan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Beschrijving</th>\n",
       "      <th>Genre</th>\n",
       "      <th>dicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "      <td>{'/m/01jfsb': 'Thriller', '/m/06n90': 'Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "      <td>{'/m/01jfsb': 'Thriller', '/m/0glj9q': 'Erotic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "      <td>{'/m/07s9rl0': 'Drama'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>{\"/m/0hqxf\": \"Family Film\", \"/m/01hmnh\": \"Fant...</td>\n",
       "      <td>{'/m/0hqxf': 'Family Film', '/m/01hmnh': 'Fant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little city</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>{\"/m/06cvj\": \"Romantic comedy\", \"/m/0hj3n0w\": ...</td>\n",
       "      <td>{'/m/06cvj': 'Romantic comedy', '/m/0hj3n0w': ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Titel  \\\n",
       "0             Ghosts of Mars   \n",
       "1           White Of The Eye   \n",
       "2          A Woman in Flames   \n",
       "3  The Sorcerer's Apprentice   \n",
       "4                Little city   \n",
       "\n",
       "                                        Beschrijving  \\\n",
       "0  Set in the second half of the 22nd century, th...   \n",
       "1  A series of murders of rich young women throug...   \n",
       "2  Eva, an upper class housewife, becomes frustra...   \n",
       "3  Every hundred years, the evil Morgana  returns...   \n",
       "4  Adam, a San Francisco-based artist who works a...   \n",
       "\n",
       "                                               Genre  \\\n",
       "0  {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...   \n",
       "1  {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...   \n",
       "2                            {\"/m/07s9rl0\": \"Drama\"}   \n",
       "3  {\"/m/0hqxf\": \"Family Film\", \"/m/01hmnh\": \"Fant...   \n",
       "4  {\"/m/06cvj\": \"Romantic comedy\", \"/m/0hj3n0w\": ...   \n",
       "\n",
       "                                               dicts  \n",
       "0  {'/m/01jfsb': 'Thriller', '/m/06n90': 'Science...  \n",
       "1  {'/m/01jfsb': 'Thriller', '/m/0glj9q': 'Erotic...  \n",
       "2                            {'/m/07s9rl0': 'Drama'}  \n",
       "3  {'/m/0hqxf': 'Family Film', '/m/01hmnh': 'Fant...  \n",
       "4  {'/m/06cvj': 'Romantic comedy', '/m/0hj3n0w': ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Omzetten van de strings naar dictionaries\n",
    "database['dicts'] = database['Genre'].apply(json.loads)\n",
    "\n",
    "# Tonen van het dataframe\n",
    "display(database.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dit is gedaan kan de dictionary worden ingelezen met een lambda functie. Deze functie zal ervoor zorgen dat de genres als een string worden ingeladen. Door dit te doen is het mogelijk om de eerste_genre functie toe te passen om ook hier alleen het eerste genre te laten staan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Beschrijving</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>Family Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little city</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>Romantic comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Titel  \\\n",
       "0             Ghosts of Mars   \n",
       "1           White Of The Eye   \n",
       "2          A Woman in Flames   \n",
       "3  The Sorcerer's Apprentice   \n",
       "4                Little city   \n",
       "\n",
       "                                        Beschrijving            Genre  \n",
       "0  Set in the second half of the 22nd century, th...         Thriller  \n",
       "1  A series of murders of rich young women throug...         Thriller  \n",
       "2  Eva, an upper class housewife, becomes frustra...            Drama  \n",
       "3  Every hundred years, the evil Morgana  returns...      Family Film  \n",
       "4  Adam, a San Francisco-based artist who works a...  Romantic comedy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Titel</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>39914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beschrijving</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>42196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Titel                        0           0.0  Categorie          -   \n",
       "Beschrijving                 0           0.0  Categorie          -   \n",
       "Genre                        0           0.0  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Titel                    39914  \n",
       "Beschrijving             42196  \n",
       "Genre                      265  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ophalen van de genres uit de dictionary\n",
    "database['Genre'] = database['dicts'].apply(lambda x: ', '.join(x.values()) if isinstance(x, dict) else x)\n",
    "\n",
    "# Toepassen van eerste_genre\n",
    "database['Genre'] = database['Genre'].apply(lambda x: eerste_genre(x, ', '))\n",
    "\n",
    "# Droppen van originele kolommen\n",
    "database = database.drop(columns=['dicts'])\n",
    "\n",
    "# Tonen van nieuw dataframe en van de informatie\n",
    "display(database.head())\n",
    "data_info(database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als laatste is de API data aan de beurt. In deze data was geen anomaly te vinden na het zien van de eerste vijf regels na het inladen. Daarom zal deze niet apart worden bekeken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Beschrijving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Les blanchisseuses</td>\n",
       "      <td>Short</td>\n",
       "      <td>This lost film presumably features women washi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dessinateur: Von Bismark</td>\n",
       "      <td>Short</td>\n",
       "      <td>This lost film featured a talented sketch arti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boxing Match; or, Glove Contest</td>\n",
       "      <td>Short</td>\n",
       "      <td>Stage boxing match between Sergeant-Instructor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plus fort que le maître</td>\n",
       "      <td>Short</td>\n",
       "      <td>Little is known about this lost film, the thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Cripple Creek Bar-Room Scene</td>\n",
       "      <td>Western</td>\n",
       "      <td>A vignette of a barroom/liquor-store in the We...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Titel    Genre  \\\n",
       "1               Les blanchisseuses    Short   \n",
       "2         Dessinateur: Von Bismark    Short   \n",
       "3  Boxing Match; or, Glove Contest    Short   \n",
       "4          Plus fort que le maître    Short   \n",
       "7     Cripple Creek Bar-Room Scene  Western   \n",
       "\n",
       "                                        Beschrijving  \n",
       "1  This lost film presumably features women washi...  \n",
       "2  This lost film featured a talented sketch arti...  \n",
       "3  Stage boxing match between Sergeant-Instructor...  \n",
       "4  Little is known about this lost film, the thir...  \n",
       "7  A vignette of a barroom/liquor-store in the We...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Toepassen van eerste genre functie\n",
    "api['Genre'] = api['Genre'].apply(lambda x: eerste_genre(x, ', '))\n",
    "\n",
    "# Tonen van de verandering\n",
    "display(api.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voordat we gaan beginnen aan het verwerken van de tekst, is het ons opgevallen dat er minder items in titel staan dan in beschrijving. Er zal dus even worden gekeken naar eventuele duplicaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Herhaalde titels:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "The Three Musketeers    9\n",
       "Dracula                 8\n",
       "Alice in Wonderland     8\n",
       "Hero                    8\n",
       "Madame X                7\n",
       "                       ..\n",
       "Between the Lines       2\n",
       "Thanksgiving            2\n",
       "Lost Horizon            2\n",
       "Thunderbolt             2\n",
       "Happy Birthday          2\n",
       "Name: Titel, Length: 1830, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'Titel'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Titel'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [database, webscraper, api]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataframes:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Kijken of er meer dan 1 van een titel voorkomt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     duplicaten \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Tonen van herhaalde titels\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHerhaalde titels:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Titel'"
     ]
    }
   ],
   "source": [
    "# Aanmaken lijst met alle dataframes\n",
    "dataframes = [database, webscraper, api]\n",
    "\n",
    "for data in dataframes:\n",
    "    # Kijken of er meer dan 1 van een titel voorkomt\n",
    "    duplicaten = data['Titel'].value_counts()[data['Titel'].value_counts() > 1]\n",
    "\n",
    "    # Tonen van herhaalde titels\n",
    "    print(f'Herhaalde titels:')\n",
    "    display(duplicaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals er te zien is, zijn er 9 films die the Three Musketeers heten. Het is belangrijk om er eerst naar te kijken voordat we doorgaan met bepalen van de handeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Beschrijving</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>When Lt. Wayne is framed for the murder of his...</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>D'Artagnan and Three Musketeers</td>\n",
       "      <td>The film consists of three parts: *Part I: \"At...</td>\n",
       "      <td>Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9878</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>Young d'Artagnan leaves his parents and travel...</td>\n",
       "      <td>Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10548</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>Callow youth D'Artagnan  sets off from Gascony...</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11349</th>\n",
       "      <td>Doraemon: Nobita and Fantastic Three Musketeers</td>\n",
       "      <td>Tired of constantly having nightmares, Nobita ...</td>\n",
       "      <td>Japanese Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13603</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>{{plot}} The young d'Artagnan wants to be a mu...</td>\n",
       "      <td>Japanese Movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19342</th>\n",
       "      <td>Barbie and the Three Musketeers</td>\n",
       "      <td>Corinne is a country girl from Gascony who dre...</td>\n",
       "      <td>Family Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>In France during the mid-19th century, Cardina...</td>\n",
       "      <td>Family Film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24493</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>The young d'Artagnan arrives in Paris with dre...</td>\n",
       "      <td>Swashbuckler films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29586</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>D'Artagnan , an inexperienced Gascon youth, tr...</td>\n",
       "      <td>Swashbuckler films</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35450</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>In Venice at the beginning of the 17th century...</td>\n",
       "      <td>Action/Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38070</th>\n",
       "      <td>The Three Musketeers</td>\n",
       "      <td>{{Plot}} In 1625 France, following in his late...</td>\n",
       "      <td>Swashbuckler films</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Titel  \\\n",
       "1229                              The Three Musketeers   \n",
       "6224                   D'Artagnan and Three Musketeers   \n",
       "9878                              The Three Musketeers   \n",
       "10548                             The Three Musketeers   \n",
       "11349  Doraemon: Nobita and Fantastic Three Musketeers   \n",
       "13603                             The Three Musketeers   \n",
       "19342                  Barbie and the Three Musketeers   \n",
       "20486                             The Three Musketeers   \n",
       "24493                             The Three Musketeers   \n",
       "29586                             The Three Musketeers   \n",
       "35450                             The Three Musketeers   \n",
       "38070                             The Three Musketeers   \n",
       "\n",
       "                                            Beschrijving               Genre  \n",
       "1229   When Lt. Wayne is framed for the murder of his...              Action  \n",
       "6224   The film consists of three parts: *Part I: \"At...             Musical  \n",
       "9878   Young d'Artagnan leaves his parents and travel...           Adventure  \n",
       "10548  Callow youth D'Artagnan  sets off from Gascony...              Action  \n",
       "11349  Tired of constantly having nightmares, Nobita ...     Japanese Movies  \n",
       "13603  {{plot}} The young d'Artagnan wants to be a mu...     Japanese Movies  \n",
       "19342  Corinne is a country girl from Gascony who dre...         Family Film  \n",
       "20486  In France during the mid-19th century, Cardina...         Family Film  \n",
       "24493  The young d'Artagnan arrives in Paris with dre...  Swashbuckler films  \n",
       "29586  D'Artagnan , an inexperienced Gascon youth, tr...  Swashbuckler films  \n",
       "35450  In Venice at the beginning of the 17th century...    Action/Adventure  \n",
       "38070  {{Plot}} In 1625 France, following in his late...  Swashbuckler films  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tonen van alle rijen met The Three Musketeers\n",
    "database[database['Titel'].str.contains('Three Musketeers')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals er te zien is zijn er verschillen in zowel het genre als de exacte beschrijvingen. Echter is het volgens ons handiger om eventuele herhaalde film titels niet uit de dataset te verwijderen. Hoewel dit ook kan leiden tot van foute voorspellingen, is het volgens ons belangrijker om de data zo te houden. Voornamelijk omdat verschillende versies van deze verhalen aantrekkelijk zijn voor andere doelgroepen. Zo is er hier bijvoorbeeld een musical, een familie film en wat actie films. Deze genres trekken vaak andere groepen aan, waardoor het belangrijk kan zijn om de data zo inclusief mogelijk te houden.\n",
    "\n",
    "Nu alle dataframes opgeschoond zijn, kan de tekst worden geprocessed. Deze taak is van belang omdat het anders erg lastig is voor een ML-algoritme om dezelfde woorden te blijven herkennen. In ons geval passen wij de volgende technieken toe om de tekst duidelijk te maken:\n",
    "\n",
    "**Stopwoorden verwijderen**<br>\n",
    "Met deze techniek worden veel gebruikte stopwoorden in de engelse taal verwijderd uit de tekst. Dit wordt gedaan om minder ruis te hebben in de tekst door te zorgen dat het algoritme niet hoeft te focussen op worden zoals the of and.\n",
    "\n",
    "**Punctuatie verwijderen**<br>\n",
    "Deze techniek wordt gebruikt om alle vormen van interpunctie uit de tekst te halen. Hoewel dit soms van belang kan zijn, is het bij filmplots vaak ruis in de tekst.\n",
    "\n",
    "**Lowercase**<br>\n",
    "Deze techniek zorgt ervoor dat alle woorden worden omgezet in lowercase versies. Dit voorkomt, bijvoorbeeld, dat het woord Auto verschillend is van auto.\n",
    "\n",
    "**Stemming**<br>\n",
    "Deze techniek brengt alle woorden, waar mogelijk, terug naar de stam van het woord. Woorden zoals lopen worden loop en rennen wordt ren. Dit zorgt ervoor dat alle verschillende vormen van de woorden hetzelfde worden begrepen door het algoritme en geeft een duidelijkere tekst weer. Deze optie is gekozen over lemmetization omdat lemmetization ervoor kan zorgen dat de betekenis van woorden verloren kan gaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_columns(df, kolom):\n",
    "    \"\"\"\n",
    "    Deze functie processed de opgegeven kolommen, zodat de\n",
    "    tekst bruikbaarder is. De opgegeven kolommen moeten\n",
    "    hiervoor wel tekstuele data bevatten.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Het dataframe waarop de aanpassingen worden uitgevoerd.\n",
    "\n",
    "    kolom : list or str\n",
    "        De kolom(men) waarop de aanpassingen worden uitgevoerd.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    df_nlp : pandas.DataFrame\n",
    "        Het dataframe waarop de toepassing zijn uitgevoert.\n",
    "    \"\"\"\n",
    "    # Het selecteren van engelse stopwoorden voor in de tekst\n",
    "    stopwoorden = set(stopwords.words('english'))\n",
    "\n",
    "    def process_text(text):\n",
    "        \"\"\"\n",
    "        Deze functies past verschillende taken\n",
    "        toe op basis van NLP technieken\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        text : str\n",
    "            Een str aan tekst in een dataframe kolom\n",
    "\n",
    "        Returns:\n",
    "        ----------\n",
    "        processed_text : str\n",
    "            Een str met de aangepaste tekst\n",
    "        \"\"\"\n",
    "        # Aanmaken van tokens in de tekst\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # Het weghalen van punctuatie binnen de tekst\n",
    "        no_punctuations = ' '.join(re.sub(r'\\W', ' ', token) for token in tokens)\n",
    "\n",
    "        # Het veranderen van alle tekst naar kleine letters\n",
    "        lower_text = no_punctuations.lower()\n",
    "\n",
    "        # Het verwijderen van de stopwoorden\n",
    "        geen_stop = ' '.join(word for word in lower_text.split() if word not in stopwoorden)\n",
    "\n",
    "        # Initieren van PorterStemmer\n",
    "        porter = PorterStemmer()\n",
    "\n",
    "        # Toepassen van stemming\n",
    "        processed_text = ' '.join(porter.stem(word) for word in word_tokenize(geen_stop))\n",
    "\n",
    "        return processed_text\n",
    "    \n",
    "    # Toepassen van tekst processing\n",
    "    df[[kolom]] = df[[kolom]].apply(lambda col: col.apply(process_text))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met de functie is het mogelijk om deze toepassingen snel uit te voeren op meerdere kolommen in de datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m kolom \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeschrijving\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Uitvoeren van de aanpassingen\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_db \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_text_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkolom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Tonen van het aangepaste dataframe\u001b[39;00m\n\u001b[0;32m      8\u001b[0m display(df_db)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_text_columns\u001b[1;34m(df, kolom)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mDeze functie processed de opgegeven kolommen, zodat de\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mtekst bruikbaarder is. De opgegeven kolommen moeten\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Het dataframe waarop de toepassing zijn uitgevoert.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Het selecteren van engelse stopwoorden voor in de tekst\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m stopwoorden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_text\u001b[39m(text):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    Deze functies past verschillende taken\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    toe op basis van NLP technieken\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m        Een str met de aangepaste tekst\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Invoeren van de kolom die aangepast worden\n",
    "kolom = 'Beschrijving'\n",
    "\n",
    "# Uitvoeren van de aanpassingen\n",
    "df_db = process_text_columns(database, kolom)\n",
    "\n",
    "# Tonen van het aangepaste dataframe\n",
    "display(df_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu we kunnen zien dat de functie goed zijn werk doet, kan deze worden toegepast op alle andere dataframes. Beginnend met de films dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Uitvoeren van de aanpassingen\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_ws \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_text_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebscraper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkolom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tonen van het aangepaste dataframe\u001b[39;00m\n\u001b[0;32m      5\u001b[0m display(df_ws)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_text_columns\u001b[1;34m(df, kolom)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mDeze functie processed de opgegeven kolommen, zodat de\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mtekst bruikbaarder is. De opgegeven kolommen moeten\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Het dataframe waarop de toepassing zijn uitgevoert.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Het selecteren van engelse stopwoorden voor in de tekst\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m stopwoorden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_text\u001b[39m(text):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    Deze functies past verschillende taken\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    toe op basis van NLP technieken\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m        Een str met de aangepaste tekst\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Uitvoeren van de aanpassingen\n",
    "df_ws = process_text_columns(webscraper, kolom)\n",
    "\n",
    "# Tonen van het aangepaste dataframe\n",
    "display(df_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu deze is getransformeerd kunnen we de code laten werken aan de API dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mzip_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Uitvoeren van de aanpassingen\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_api \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_text_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkolom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Tonen van het aangepaste dataframe\u001b[39;00m\n\u001b[0;32m      5\u001b[0m display(df_api)\n",
      "Input \u001b[1;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_text_columns\u001b[1;34m(df, kolom)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mDeze functie processed de opgegeven kolommen, zodat de\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mtekst bruikbaarder is. De opgegeven kolommen moeten\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    Het dataframe waarop de toepassing zijn uitgevoert.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Het selecteren van engelse stopwoorden voor in de tekst\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m stopwoorden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mstopwords\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwords\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_text\u001b[39m(text):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    Deze functies past verschillende taken\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    toe op basis van NLP technieken\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m        Een str met de aangepaste tekst\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLazyCorpusLoader object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__bases__\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubdir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__reader_cls(root, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubdir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Gebruiker/nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Gebruiker\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Uitvoeren van de aanpassingen\n",
    "df_api = process_text_columns(api, kolom)\n",
    "\n",
    "# Tonen van het aangepaste dataframe\n",
    "display(df_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu ze allemaal een verwerkte tekst hebben is het belangrijk om ze samen te voegen voordat we features aan gaan maken. Dit is om te voorkomen dat er vervolgens te veel features gaan ontstaan door het koppelen van 3 verschillende datasets. Dit zal gebeuren door de dataframes op elkaar te gaan stacken, dit houdt in dat ze op elkaar gestapeled worden. Dit is mogelijk omdat we bij het inladen van de dataset hebben gelet op welke kolommen we wilden gebruiken en hoe we deze noemden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missende_waarden</th>\n",
       "      <th>Perc_missend</th>\n",
       "      <th>Type</th>\n",
       "      <th>Nulwaarden</th>\n",
       "      <th>Aantal_Categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Titel</th>\n",
       "      <td>1000</td>\n",
       "      <td>2.28</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>40459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beschrijving</th>\n",
       "      <td>1000</td>\n",
       "      <td>2.28</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>42803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <td>1000</td>\n",
       "      <td>2.28</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Film</th>\n",
       "      <td>42822</td>\n",
       "      <td>97.72</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omschrijving</th>\n",
       "      <td>42822</td>\n",
       "      <td>97.72</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genres</th>\n",
       "      <td>42822</td>\n",
       "      <td>97.72</td>\n",
       "      <td>Categorie</td>\n",
       "      <td>-</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Missende_waarden  Perc_missend       Type Nulwaarden  \\\n",
       "Titel                     1000          2.28  Categorie          -   \n",
       "Beschrijving              1000          2.28  Categorie          -   \n",
       "Genre                     1000          2.28  Categorie          -   \n",
       "Film                     42822         97.72  Categorie          -   \n",
       "Omschrijving             42822         97.72  Categorie          -   \n",
       "Genres                   42822         97.72  Categorie          -   \n",
       "\n",
       "              Aantal_Categorie  \n",
       "Titel                    40459  \n",
       "Beschrijving             42803  \n",
       "Genre                      267  \n",
       "Film                       994  \n",
       "Omschrijving              1000  \n",
       "Genres                     194  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Beschrijving</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Film</th>\n",
       "      <th>Omschrijving</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>Set in the second half of the 22nd century, th...</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>A series of murders of rich young women throug...</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>Eva, an upper class housewife, becomes frustra...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Sorcerer's Apprentice</td>\n",
       "      <td>Every hundred years, the evil Morgana  returns...</td>\n",
       "      <td>Family Film</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little city</td>\n",
       "      <td>Adam, a San Francisco-based artist who works a...</td>\n",
       "      <td>Romantic comedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Titel  \\\n",
       "0             Ghosts of Mars   \n",
       "1           White Of The Eye   \n",
       "2          A Woman in Flames   \n",
       "3  The Sorcerer's Apprentice   \n",
       "4                Little city   \n",
       "\n",
       "                                        Beschrijving            Genre Film  \\\n",
       "0  Set in the second half of the 22nd century, th...         Thriller  NaN   \n",
       "1  A series of murders of rich young women throug...         Thriller  NaN   \n",
       "2  Eva, an upper class housewife, becomes frustra...            Drama  NaN   \n",
       "3  Every hundred years, the evil Morgana  returns...      Family Film  NaN   \n",
       "4  Adam, a San Francisco-based artist who works a...  Romantic comedy  NaN   \n",
       "\n",
       "  Omschrijving Genres  \n",
       "0          NaN    NaN  \n",
       "1          NaN    NaN  \n",
       "2          NaN    NaN  \n",
       "3          NaN    NaN  \n",
       "4          NaN    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Het 'stacken' van de dataframes\n",
    "stacked_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Tonen van het resultaat\n",
    "data_info(stacked_df)\n",
    "display(stacked_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu dit is gedaan kunnen we door met Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:20px; font-weight:bold;\">Feature Engineering</div>\n",
    "</div>\n",
    "\n",
    "Nu alle gegevens zijn gepreprocessed, kan er worden gewerkt aan het maken van de features. Deze stap, genaamd feature engineering, is eigenlijk een stap die de diepte ingaat ten opzichte van preprocessing. Een groot verschil tussen de twee stappen is dat bij Feature Engineering deze kolommen niet meer worden aangepast voor begrip, maar om het model beter te laten presteren. Dit houdt onder andere in dat ruwe data zoals tekst, video of audio omgezet gaan worden van bruikbaar naar nuttig. Om met de features in onze data te beginnen zal er gewerkt worden aan de TF-IDF feature.\n",
    "\n",
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:15px; font-weight:bold;\">TF-IDF (Term Frequency - Inverse Document Frequency)</div>\n",
    "</div>\n",
    "\n",
    "TF-IDF is een statistische maatstaf die het belang van een woord in een tekst berekent. Het is gebaseerd op twee componenten: Term Frequency (TF) en Inverse Document Frequency (IDF).\n",
    "\n",
    "Term Frequency (TF): Dit geeft aan hoe vaak een woord voorkomt in een document. Het wordt berekend door het aantal keren dat een woord voorkomt te delen door het totale aantal woorden in het document. Dit wordt weergegeven als $TF(t, d)$, waarbij t de term of woord is en d het document of de tekst.\n",
    "\n",
    "Inverse Document Frequency (IDF): Dit geeft het omgekeerde van de frequentie van het woord over alle documenten in de dataset aan. Het wordt berekend door het totale aantal documenten te delen door het aantal documenten waarin het woord voorkomt, en de uitkomst te logaritmeren. Dit uit zich in de formule als $IDF(t)$, dit staat eigenlijk voor $\\log{\\frac{1 + n}{1 + df(d, t)}}+1$. Hierbij is $n$ het aantal documenten en $df(d, t)$ het aantal documenten waar de term in voorkomt.\n",
    "\n",
    "Dit geheel uit zich dan in de volgende formule:\n",
    "\n",
    "$TFIDF = TF(t, d) × IDF(t)$\n",
    "\n",
    "Met TF-IDF kunnen we het belang van woorden in een tekst begrijpen en benadrukken, wat nuttig is voor taken zoals tekstclassificatie, clustering en informatieherwinning. Door dit te gebruiken met ondersteuning van Truncated SVD, is het mogelijk om het aantal features ook te beperken. Dit is van belang omdat de code anders te veel geheugen gebruikt omdat er te veel feature kolommen worden aangemaakt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Apply the function to add reduced TF-IDF features\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstacked_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkolom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBeschrijving\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponenten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Display the DataFrame with added features\u001b[39;00m\n\u001b[0;32m     46\u001b[0m display(data\u001b[38;5;241m.\u001b[39mhead())\n",
      "Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mtfidf_features\u001b[1;34m(df, kolom, componenten)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# TF-IDF Vectorization\u001b[39;00m\n\u001b[0;32m     26\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m---> 27\u001b[0m tfidf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf_vectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Truncated SVD for Dimensionality Reduction\u001b[39;00m\n\u001b[0;32m     30\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39mcomponenten, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2139\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2134\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2135\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2136\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2137\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2138\u001b[0m )\n\u001b[1;32m-> 2139\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2141\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2142\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1386\u001b[0m             )\n\u001b[0;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[0;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:105\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:238\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    235\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "def tfidf_features(df, kolom, componenten=100):\n",
    "    \"\"\"\n",
    "    Deze functie past TF-IDF vectorizatie toe met\n",
    "    dimensionaliteits reductie door middel van Truncated SVD.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Het dataframe dat de teksten bevat.\n",
    "\n",
    "    kolom : str\n",
    "        De kolomnaam van het dataframe met teksten\n",
    "\n",
    "    componenten : int\n",
    "        Het aantal componenten voor Truncated SVD\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    data : pandas.DataFrame\n",
    "        Het oude dataframe met de features erin.\n",
    "    \"\"\"\n",
    "    # Extract text from the specified column\n",
    "    texts = df[kolom]\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "    # Truncated SVD for Dimensionality Reduction\n",
    "    svd = TruncatedSVD(n_components=componenten, random_state=42)\n",
    "    reduced_tfidf = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "    # Create DataFrame with reduced TF-IDF features\n",
    "    feature_names = [f\"tfidf_{i}\" for i in range(componenten)]\n",
    "    df_tfidf = pd.DataFrame(reduced_tfidf, columns=feature_names)\n",
    "\n",
    "    # Concatenate the new features with the original DataFrame\n",
    "    data = pd.concat([df, df_tfidf], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "# Apply the function to add reduced TF-IDF features\n",
    "data = tfidf_features(stacked_df, kolom=\"Beschrijving\", componenten=100)\n",
    "\n",
    "# Display the DataFrame with added features\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Opzetten van de Pipeline</div>\n",
    "    <a name='pipe'></a>\n",
    "</div>\n",
    "\n",
    "Om te zorgen dat alle data op de juiste manier word ingeladen en getransformeerd maken we gebruik van een pipeline. De pipeline is eigenlijk een class vol met functies die ons helpt om data gemakkelijk in te laden en te transformeren. De functies in de pipeline zijn zo robuust mogelijk opgesteld, zodat er geen problemen zijn bij het inladen en verwerken van een andere databron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_columns(df, column):\n",
    "    stopwoorden = set(stopwords.words('english'))\n",
    "\n",
    "    def process_text(text):\n",
    "        tokens = word_tokenize(text)\n",
    "        no_punctuations = ' '.join(re.sub(r'\\W', ' ', token) for token in tokens)\n",
    "        lower_text = no_punctuations.lower()\n",
    "        geen_stop = ' '.join(word for word in lower_text.split() if word not in stopwoorden)\n",
    "        porter = PorterStemmer()\n",
    "        processed_text = ' '.join(porter.stem(word) for word in word_tokenize(geen_stop))\n",
    "        return processed_text\n",
    "\n",
    "    # Apply the process_text function to each element in the specified column\n",
    "    df[column] = df[column].apply(process_text)\n",
    "\n",
    "    return df\n",
    "\n",
    "def eerste_genre(tekst, splitter):\n",
    "    \"\"\"\n",
    "    Deze functie maakt van een string aan genres een\n",
    "    enkel genre. Dit genre is degene die als eerste\n",
    "    in de string voorkomt.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    tekst : str\n",
    "        Een string die de genres bevat, deze bevat voor elke\n",
    "        split hetzelfde te herkennen gedeelte. Bijv.: ', '.\n",
    "    \n",
    "    splitter : str\n",
    "        Het string gedeelte waarop de tekst wordt gesplitst.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Split de tekst in delen aan de hang van ', '\n",
    "    genres = tekst.split(splitter)\n",
    "\n",
    "    # Selecteer het eerste genre\n",
    "    eerste_genre = genres[0]\n",
    "\n",
    "    return eerste_genre\n",
    "\n",
    "def tfidf_with_dimensionality_reduction(df, kolom, num_components=100):\n",
    "    \"\"\"\n",
    "    Voert TF-IDF vectorisatie uit en reduceert de dimensionaliteit met Truncated SVD.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        Het DataFrame met de tekstuele documenten.\n",
    "    kolom : str\n",
    "        De naam van de kolom met de tekstuele documenten.\n",
    "    num_components : int, optional\n",
    "        Het aantal componenten voor Truncated SVD. Standaard is 100.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Het input DataFrame met toegevoegde gereduceerde TF-IDF functies.\n",
    "    \"\"\"\n",
    "    # Haal de tekst op uit kolom\n",
    "    teksten = df[kolom]\n",
    "\n",
    "    # TF-IDF Vectorisatie\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(teksten)\n",
    "\n",
    "    # Truncated SVD voor Dimensionaliteitsreductie\n",
    "    svd = TruncatedSVD(n_components=num_components, random_state=42)\n",
    "    red_tfidf = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "    # Maak een DataFrame met TF-IDF kolommen\n",
    "    tfidf_cols = [f\"tfidf_{i}\" for i in range(num_components)]\n",
    "    df_tfidf = pd.DataFrame(red_tfidf, columns=tfidf_cols)\n",
    "\n",
    "    # voeg data samen\n",
    "    data = pd.concat([df, df_tfidf], axis=1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ETL_Pipeline:\n",
    "    \"\"\"\n",
    "    Class voor een Extract-Transform-Load Pipeline.\n",
    "    Deze class kan nodige data van een database, API of\n",
    "    webscraping bron halen. Deze data kan vervolgens\n",
    "    getransformeerd worden, waarna de data kan worden\n",
    "    ingeladen in een pandas DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, db_source=None, query=None, api_source=None, csv_file=None, headers=None):\n",
    "        \"\"\"\n",
    "        Initiator van de class. De initiator neemt bepaalde\n",
    "        waarden op. Met behulp van deze waarden kunnen de\n",
    "        functies worden uitgevoerd.\n",
    "        \"\"\"\n",
    "        self.db_source = db_source\n",
    "        self.query = query\n",
    "        self.api_source = api_source\n",
    "        self.csv_file = csv_file\n",
    "        self.data_frame = pd.DataFrame()\n",
    "        self.headers = headers\n",
    "\n",
    "    def extract_db(self):\n",
    "        \"\"\"\n",
    "        Deze functie haalt data op uit een lokale database.\n",
    "        \"\"\"\n",
    "        # Verbinden met de database\n",
    "        conn = sqlite3.connect(self.db_source)\n",
    "\n",
    "        # Uitvoeren van de query op de database\n",
    "        db_data = pd.read_sql_query(self.query, conn)\n",
    "\n",
    "        # Sluiten van de verbinding met de database\n",
    "        conn.close()\n",
    "\n",
    "        return db_data\n",
    "\n",
    "    def extract_api(self):\n",
    "        \"\"\"\n",
    "        Deze functie haalt data op uit ruwe bronnen.\n",
    "        \"\"\"\n",
    "        resultaten = []\n",
    "\n",
    "        # Itereer over de paginanummers\n",
    "        for page_number in range(1, 21):\n",
    "            \n",
    "            querystring = {\n",
    "                \"page\": str(page_number),\n",
    "                \"info\": \"base_info\",\n",
    "                \"limit\": \"50\"\n",
    "            }\n",
    "\n",
    "            response = requests.get(url, headers=headers, params=querystring)\n",
    "\n",
    "            # Check if the request was successful (status code 200)\n",
    "            if response.status_code == 200:\n",
    "                # Itereer over elk resultaat in de 'results' lijst van de JSON-respons\n",
    "                json_response = response.json()\n",
    "                if 'results' in json_response:\n",
    "                    for resultaat in json_response['results']:\n",
    "                        # Haal de benodigde velden op\n",
    "                        titel = resultaat['titleText']['text'] if 'titleText' in resultaat else np.nan\n",
    "\n",
    "                        # Check if 'genres' is present and not None\n",
    "                        if 'genres' in resultaat and resultaat['genres']:\n",
    "                            # Use ', '.join() to convert the list of genres into a comma-separated string\n",
    "                            genres = ', '.join([genre['text'] for genre in resultaat['genres']['genres']])\n",
    "                        else:\n",
    "                            genres = np.nan\n",
    "\n",
    "                        plot = resultaat['plot']['plotText']['plainText'] if 'plot' in resultaat and resultaat['plot'] and 'plotText' in resultaat['plot'] else np.nan\n",
    "\n",
    "                        # Voeg de resultaten toe aan de lijst\n",
    "                        resultaten.append({\n",
    "                            'Titel': titel,\n",
    "                            'Beschrijving': plot,\n",
    "                            'Genre': genres\n",
    "                        })\n",
    "                else:\n",
    "                    print(f\"Error: 'results' not found in JSON response for page {page_number}\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Error: Request failed with status code {response.status_code}\")\n",
    "\n",
    "        api_data = pd.DataFrame(resultaten)\n",
    "\n",
    "        return api_data\n",
    "\n",
    "    def extract_csv(self):\n",
    "        \"\"\"\n",
    "        Deze functie haalt data op uit ruwe bronnen.\n",
    "        \"\"\"\n",
    "        # Inlezen van csv data\n",
    "        csv_data = pd.read_csv(self.csv_file)\n",
    "\n",
    "        return csv_data\n",
    "\n",
    "    def transform_data(self, data_frames):\n",
    "        def process_genre(x):\n",
    "            try:\n",
    "                genre_dict = json.loads(x)\n",
    "                return ', '.join(genre_dict.values()) if isinstance(genre_dict, dict) else x\n",
    "            except (json.JSONDecodeError, AttributeError):\n",
    "                return x\n",
    "\n",
    "        def process_dataframe(dataframe):\n",
    "            dataframe.dropna(subset=['Beschrijving', 'Genre', 'Titel'], inplace=True)\n",
    "            dataframe['Genre'] = dataframe['Genre'].apply(process_genre)\n",
    "            dataframe['Genre'] = dataframe['Genre'].apply(lambda x: eerste_genre(x, ', '))\n",
    "            dataframe.drop(columns=['dicts'], inplace=True, errors='ignore')\n",
    "            return dataframe\n",
    "\n",
    "        data_frames = [process_dataframe(df) for df in data_frames]\n",
    "\n",
    "        stacked_data = pd.concat(data_frames, ignore_index=True)\n",
    "        stacked_data.dropna(subset=['Beschrijving'], inplace=True)\n",
    "\n",
    "        preprocessed_data = process_text_columns(stacked_data, 'Beschrijving')\n",
    "        transformed_data = tfidf_with_dimensionality_reduction(preprocessed_data, text_column=\"Beschrijving\", num_components=100)\n",
    "\n",
    "        return transformed_data\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Deze functie laad de data in naar een\n",
    "        pandas.DataFrame.\n",
    "        \"\"\"\n",
    "        # Maken van lege lijst voor databronnen\n",
    "        all_data_frames = []\n",
    "\n",
    "        # Extraheer data van gebruikte bronnen\n",
    "        if self.db_source:\n",
    "            db_data = self.extract_db()\n",
    "            all_data_frames.append(db_data)\n",
    "        if self.api_source:\n",
    "            api_data = self.extract_api()\n",
    "            all_data_frames.append(api_data)\n",
    "        if self.csv_file:\n",
    "            csv_data = self.extract_csv()\n",
    "            all_data_frames.append(csv_data)\n",
    "\n",
    "        # Transformeer en merge alle data\n",
    "        transformed_data = self.transform_data(all_data_frames)\n",
    "\n",
    "        # Toewijzen van de data aan de data_frame class attribuut\n",
    "        self.data_frame = transformed_data\n",
    "\n",
    "        return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu de Pipeline is aangemaakt, kunnen de parameters worden gedefined. De parameters zijn opzettelijk los neergezet, om de Pipeline niet vast te zetten in het geval van kleine aanpassingen aan de locaties van bestanden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoeren van de DataBase naam\n",
    "db_source = \"movie_database.db\"\n",
    "\n",
    "# Invoeren van query op DataBase\n",
    "query = \"\"\"\n",
    "    SELECT mm.Titel,\n",
    "           ps.Beschrijving,\n",
    "           mm.Genre\n",
    "    FROM 'movie.metadata' AS mm\n",
    "        \n",
    "    JOIN 'plot_summaries' AS ps\n",
    "        ON mm.Wikipedia_ID = ps.Wikipedia_ID\n",
    "\"\"\"\n",
    "\n",
    "# Invoeren van de API link\n",
    "api_source = \"https://moviesdatabase.p.rapidapi.com/titles\"\n",
    "\n",
    "querystring = {\"limit\":\"50\",\"info\":\"base_info\"}\n",
    "\n",
    "headers = {\n",
    "    \"X-RapidAPI-Key\": \"862efd2e3dmsh364685e1c50acb8p153999jsnd3c8b4543ef9\",\n",
    "    \"X-RapidAPI-Host\": \"moviesdatabase.p.rapidapi.com\"\n",
    "}\n",
    "\n",
    "# Invoeren van csv file path\n",
    "csv_file = \"IMDb_data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Met alle nodige parameters gedefinieerd, kan de pipeline worden gebruikt om de data in te laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['Beschrijving', 'Genre', 'Titel']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m etl \u001b[38;5;241m=\u001b[39m ETL_Pipeline(db_source\u001b[38;5;241m=\u001b[39mdb_source,\n\u001b[0;32m      2\u001b[0m                    query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m      3\u001b[0m                    api_source\u001b[38;5;241m=\u001b[39mapi_source,\n\u001b[0;32m      4\u001b[0m                    csv_file\u001b[38;5;241m=\u001b[39mcsv_file,\n\u001b[0;32m      5\u001b[0m                    headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43metl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mETL_Pipeline.load_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m     all_data_frames\u001b[38;5;241m.\u001b[39mappend(csv_data)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Transformeer en merge alle data\u001b[39;00m\n\u001b[1;32m--> 142\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# Toewijzen van de data aan de data_frame class attribuut\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_frame \u001b[38;5;241m=\u001b[39m transformed_data\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mETL_Pipeline.transform_data\u001b[1;34m(self, data_frames)\u001b[0m\n\u001b[0;32m    109\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdicts\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n\u001b[1;32m--> 112\u001b[0m data_frames \u001b[38;5;241m=\u001b[39m [process_dataframe(df) \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m data_frames]\n\u001b[0;32m    114\u001b[0m stacked_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(data_frames, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    115\u001b[0m stacked_data\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeschrijving\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    109\u001b[0m     dataframe\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdicts\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n\u001b[1;32m--> 112\u001b[0m data_frames \u001b[38;5;241m=\u001b[39m [\u001b[43mprocess_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m data_frames]\n\u001b[0;32m    114\u001b[0m stacked_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(data_frames, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    115\u001b[0m stacked_data\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBeschrijving\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [31]\u001b[0m, in \u001b[0;36mETL_Pipeline.transform_data.<locals>.process_dataframe\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_dataframe\u001b[39m(dataframe):\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBeschrijving\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGenre\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenre\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(process_genre)\n\u001b[0;32m    108\u001b[0m     dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenre\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataframe[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenre\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: eerste_genre(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6002\u001b[0m, in \u001b[0;36mDataFrame.dropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   6000\u001b[0m     check \u001b[38;5;241m=\u001b[39m indices \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   6001\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m-> 6002\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(np\u001b[38;5;241m.\u001b[39marray(subset)[check]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m   6003\u001b[0m     agg_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indices, axis\u001b[38;5;241m=\u001b[39magg_axis)\n\u001b[0;32m   6005\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: ['Beschrijving', 'Genre', 'Titel']"
     ]
    }
   ],
   "source": [
    "etl = ETL_Pipeline(db_source=db_source,\n",
    "                   query=query,\n",
    "                   api_source=api_source,\n",
    "                   csv_file=csv_file,\n",
    "                   headers=headers)\n",
    "\n",
    "df = etl.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het dataframe dat wij uit onze pipeline krijgen heeft .... rijen en 3 kolommen. De kolommen bestaan uit de titel van de film, het genre, een (korte) omschrijving van de film en features .... . Sommige omschrijvingen bestaan uit een paar zinnen en sommige bestaan uit grote alinea's. Nu het dataframe af is, kan het datascience team aan de slag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Aantonen dat de Pipeline werkt</div>\n",
    "    <a name='toon'></a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het voorspellen van het genre is een classificatie probleem, want je gaat de films classificeren op basis van het genre. Daarom kiezen wij voor een decisiontree model om aantetonen dat de pipeline werkt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y definiëren\n",
    "X = df.drop(['genre','titel', 'beschrijving'], axis=1)\n",
    "y = df['genre']\n",
    "\n",
    "# Toepassen van train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "#het model fitten\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# accuracy berekenen\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Nauwkeurigheid: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dt= {\n",
    "    'criterion': ['gini', 'entropy'],  \n",
    "    'splitter': ['best', 'random'],    \n",
    "    'max_depth': [None, 5, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],   \n",
    "    'min_samples_leaf': [1, 2, 4],    \n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]  \n",
    "}\n",
    "\n",
    "#gridsearch toepassen zodat de beste parameters worden gekozen\n",
    "gs = GridSearchCV(estimator=dt,\n",
    "                    param_grid=param_dt,\n",
    "                    cv=cv,\n",
    "                    scoring='accuracy',\n",
    "                    n_jobs=-1)\n",
    "    \n",
    "# Fitten van de grid search\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "# Tonen van de beste score en parameters\n",
    "print(f\"Beste accuracy: {gs.best_score_}\")\n",
    "print(f\"Beste parameters:\\n{gs.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#600170; color:#fff; padding:10px; border-radius:5px; display: flex; justify-content: center; align-items: center; position: relative;\">\n",
    "    <div style=\"font-size:40px; font-weight:bold;\">Bronnen</div>\n",
    "    <a name='bron'></a>\n",
    "</div>\n",
    "\n",
    "Please cite this paper if you write any papers involving the use of the data (van de Movie Summary Corpus):\n",
    "\n",
    "    Learning Latent Personas of Film Characters\n",
    "    David Bamman, Brendan O'Connor, and Noah A. Smith\n",
    "    ACL 2013, Sofia, Bulgaria, August 2013\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
